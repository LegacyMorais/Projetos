{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "sjV763VvWzM6",
        "0RdcD4TOW3aO",
        "fT6khTE4dwd2",
        "czYyeJMpl4wU",
        "r_gP4q_Ll7_d",
        "i4f8IPmNsjin",
        "U9oOkXtXsjix",
        "XbUaD245sji0"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ALL IMPORTS NECESSARY ARE HERE AT THE TOP"
      ],
      "metadata": {
        "id": "sjV763VvWzM6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tg4Fs_FogHv4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71bd43fc-a30e-4f66-c4a2-cf1177fc32e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.11.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.1\n",
            "    Uninstalling numpy-1.25.1:\n",
            "      Successfully uninstalled numpy-1.25.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n",
            "flax 0.7.0 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n",
            "orbax-checkpoint 0.2.7 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from google.colab import drive\n",
        "from scipy.interpolate import interp1d\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "!pip install tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=pt-br"
      ],
      "metadata": {
        "id": "a4MVQGQdOcj7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# READING THE DATA"
      ],
      "metadata": {
        "id": "0RdcD4TOW3aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_paths = [\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario1.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario2.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario3.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario4.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario5.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario6.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario7.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario8.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario9.mat'\n",
        "]\n",
        "\n",
        "file_data = []\n",
        "df = []\n",
        "\n",
        "for i, file_path in enumerate(file_paths):\n",
        "    print(f\"Reading File: {file_path}\")\n",
        "    data = sio.loadmat(file_path)\n",
        "    df.append(pd.DataFrame(data['data'], columns=['ALE', 'NLE', 'ALD', 'NLD','S4_y1', 'S4_z1', 'S1_y1', 'S1_z1', 'S2_y1', 'S2_z1', 'S3_y1', 'S3_z1', 'Label']))"
      ],
      "metadata": {
        "id": "aL1igPK3sOny",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e28fec1b-5615-4fe7-d74e-21c0285484ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario1.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario2.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario3.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario4.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario5.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario6.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario7.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario8.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario9.mat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RF REGRESSOR"
      ],
      "metadata": {
        "id": "9BjAdUh-sW-5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1%"
      ],
      "metadata": {
        "id": "fT6khTE4dwd2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = df[0]\n",
        "dataset2 = df[1]\n",
        "dataset3 = df[2]\n",
        "dataset4 = df[3]\n",
        "dataset5 = df[4]\n",
        "dataset6 = df[5]\n",
        "dataset7 = df[6]\n",
        "dataset8 = df[7]\n",
        "dataset9 = df[8]\n",
        "\n",
        "dataset1 = dataset1[:10000]\n",
        "dataset2 = dataset2[:10000]\n",
        "dataset3 = dataset3[:10000]\n",
        "dataset4 = dataset4[:10000]\n",
        "dataset5 = dataset5[:10000]\n",
        "dataset6 = dataset6[:10000]\n",
        "dataset7 = dataset7[:10000]\n",
        "dataset8 = dataset8[:10000]\n",
        "dataset9 = dataset9[:10000]\n",
        "\n",
        "print(\"Datasets read successfully\")"
      ],
      "metadata": {
        "id": "jP85x6rR4Ybp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f3df023-ea1b-4066-e60c-224418caab2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets read successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN STEP 1 REGRESSOR - RANDOM FOREST"
      ],
      "metadata": {
        "id": "DxnkHmcS3w1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate datasets 1, 2, 3, 4, 5, 7, 8, and 9 for training\n",
        "#train_datasets = [dataset1_sample, dataset2_sample, dataset3_sample, dataset4_sample, dataset5_sample, dataset7_sample, dataset8_sample, dataset9_sample]\n",
        "\n",
        "train_datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9]\n",
        "\n",
        "train_data = pd.concat(train_datasets).reset_index(drop=True)\n",
        "\n",
        "# Separate the training data into features (X) and irregularity data (y)\n",
        "X = train_data.iloc[:, 4:-1]  # Only acceleration data\n",
        "y = train_data[['ALE', 'NLE', 'ALD', 'NLD']]  # Irregularity data\n",
        "z = train_data.iloc[:, -1]\n",
        "\n",
        "# Create the scaler and scale the training features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, z_train, z_test = train_test_split(X_scaled, y, z, test_size=0.1, random_state=42)\n",
        "\n",
        "# Step 1: Train a Random Forest regression model for irregularity prediction\n",
        "irregularity_model = RandomForestRegressor(n_estimators=50, random_state=42, verbose = 2)\n",
        "irregularity_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict irregularity for the training data\n",
        "irregularity_predictions = irregularity_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate evaluation metrics for Step 1\n",
        "mse = mean_squared_error(y_train, irregularity_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_train, irregularity_predictions)\n",
        "r2 = r2_score(y_train, irregularity_predictions)\n",
        "\n",
        "# Print the evaluation metrics for Step 1\n",
        "print(\"Metrics for the RF Regressor - 1%\")\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Step 2: Train an SVC model for damage prediction\n",
        "X_train_combined = np.column_stack((X_train_scaled, irregularity_predictions))"
      ],
      "metadata": {
        "id": "JX-nC6SSXDU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b53674cf-766e-45e3-df37-7e87174cf2a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 1 of 50\n",
            "building tree 2 of 50\n",
            "building tree 3 of 50\n",
            "building tree 4 of 50\n",
            "building tree 5 of 50\n",
            "building tree 6 of 50\n",
            "building tree 7 of 50\n",
            "building tree 8 of 50\n",
            "building tree 9 of 50\n",
            "building tree 10 of 50\n",
            "building tree 11 of 50\n",
            "building tree 12 of 50\n",
            "building tree 13 of 50\n",
            "building tree 14 of 50\n",
            "building tree 15 of 50\n",
            "building tree 16 of 50\n",
            "building tree 17 of 50\n",
            "building tree 18 of 50\n",
            "building tree 19 of 50\n",
            "building tree 20 of 50\n",
            "building tree 21 of 50\n",
            "building tree 22 of 50\n",
            "building tree 23 of 50\n",
            "building tree 24 of 50\n",
            "building tree 25 of 50\n",
            "building tree 26 of 50\n",
            "building tree 27 of 50\n",
            "building tree 28 of 50\n",
            "building tree 29 of 50\n",
            "building tree 30 of 50\n",
            "building tree 31 of 50\n",
            "building tree 32 of 50\n",
            "building tree 33 of 50\n",
            "building tree 34 of 50\n",
            "building tree 35 of 50\n",
            "building tree 36 of 50\n",
            "building tree 37 of 50\n",
            "building tree 38 of 50\n",
            "building tree 39 of 50\n",
            "building tree 40 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  2.5min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 41 of 50\n",
            "building tree 42 of 50\n",
            "building tree 43 of 50\n",
            "building tree 44 of 50\n",
            "building tree 45 of 50\n",
            "building tree 46 of 50\n",
            "building tree 47 of 50\n",
            "building tree 48 of 50\n",
            "building tree 49 of 50\n",
            "building tree 50 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    1.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for the RF Regressor - 1%\n",
            "RMSE: 0.331939048644776\n",
            "R2: 0.8897175100354501\n",
            "MAE: 0.2303126413482636\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = SVC(kernel='rbf')\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54VZF09mMuNf",
        "outputId": "7f42082c-8ffb-433e-c957-4e25038fe037"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.2726\n",
            "Recall: 0.4114\n",
            "F1-score: 0.3279\n",
            "Accuracy: 0.5814\n",
            "True Positives (TP): 919\n",
            "False Positives (FP): 2452\n",
            "True Negatives (TN): 4314\n",
            "False Negatives (FN): 1315\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier LightGBM"
      ],
      "metadata": {
        "id": "_yXQW1xI4EQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "gnUFWrzy4KbT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0adea72-8340-40af-e70e-d555915d06fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.2955\n",
            "Recall: 0.4123\n",
            "F1-score: 0.3442\n",
            "Accuracy: 0.6101\n",
            "True Positives (TP): 921\n",
            "False Positives (FP): 2196\n",
            "True Negatives (TN): 4570\n",
            "False Negatives (FN): 1313\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier NEURAL NETWORK"
      ],
      "metadata": {
        "id": "OKGn0ZrA13Ul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a neural network model for damage prediction\n",
        "damage_model5 = Sequential()\n",
        "damage_model5.add(Dense(64, activation='relu', input_dim=X_train_combined.shape[1]))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(1, activation='sigmoid'))  # Output neuron for damage classification\n",
        "\n",
        "damage_model5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "damage_model5.fit(X_train_combined, z_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model5.predict(X_test_combined)\n",
        "\n",
        "# Convert damage probabilities to binary predictions using a threshold\n",
        "threshold = 0.5\n",
        "damage_predictions = (damage_predictions > threshold).astype(int)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsTp16eR1yq_",
        "outputId": "cde7747d-0f0e-4e42-ae60-4c6dcb4f62bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2532/2532 [==============================] - 14s 3ms/step - loss: 0.0792 - accuracy: 0.9622\n",
            "Epoch 2/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0455 - accuracy: 0.9794\n",
            "Epoch 3/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0403 - accuracy: 0.9823\n",
            "Epoch 4/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0380 - accuracy: 0.9835\n",
            "Epoch 5/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0372 - accuracy: 0.9836\n",
            "Epoch 6/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0361 - accuracy: 0.9842\n",
            "Epoch 7/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0352 - accuracy: 0.9840\n",
            "Epoch 8/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0339 - accuracy: 0.9851\n",
            "Epoch 9/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0339 - accuracy: 0.9853\n",
            "Epoch 10/10\n",
            "2532/2532 [==============================] - 7s 3ms/step - loss: 0.0330 - accuracy: 0.9856\n",
            "  1/282 [..............................] - ETA: 23s"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "282/282 [==============================] - 0s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.2697\n",
            "Recall: 0.4315\n",
            "F1-score: 0.3319\n",
            "Accuracy: 0.5688\n",
            "True Positives (TP): 964\n",
            "False Positives (FP): 2611\n",
            "True Negatives (TN): 4155\n",
            "False Negatives (FN): 1270\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier XGBoost"
      ],
      "metadata": {
        "id": "SmutACQ43mh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train an XGBoost classifier for damage prediction\n",
        "damage_model2 = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "damage_model2.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model2.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "gP2qi7zW37xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1aca9dfd-efa4-4dc0-a993-e615eda3edf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.2864\n",
            "Recall: 0.4002\n",
            "F1-score: 0.3339\n",
            "Accuracy: 0.6037\n",
            "True Positives (TP): 894\n",
            "False Positives (FP): 2227\n",
            "True Negatives (TN): 4539\n",
            "False Negatives (FN): 1340\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier RANDOM FOREST"
      ],
      "metadata": {
        "id": "0xVXWj-EHe7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a Random Forest classifier for damage prediction\n",
        "damage_model6 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "damage_model6.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model6.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "nxLvaeuOGCFv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff81a7a-dea2-41d5-8d99-5babf6b312b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.3089\n",
            "Recall: 0.3563\n",
            "F1-score: 0.3309\n",
            "Accuracy: 0.6423\n",
            "True Positives (TP): 796\n",
            "False Positives (FP): 1781\n",
            "True Negatives (TN): 4985\n",
            "False Negatives (FN): 1438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier Thresholds"
      ],
      "metadata": {
        "id": "PItpOeFNrKIv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict irregularity for the testing data\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "\n",
        "# Compare the predicted irregularities with a threshold to predict damage\n",
        "threshold_ale = 1.5e-3\n",
        "threshold_nle = 2.3e-3\n",
        "threshold_ald = 1.5e-3\n",
        "threshold_nld = 2.3e-3\n",
        "\n",
        "predicted_labels = []\n",
        "for i in range(len(irregularity_predictions)):\n",
        "    if (irregularity_predictions[i, 0] > threshold_ale) or (irregularity_predictions[i, 1] > threshold_nle) or (irregularity_predictions[i, 2] > threshold_ald) or (irregularity_predictions[i, 3] > threshold_nld):\n",
        "        predicted_labels.append(1)\n",
        "    else:\n",
        "        predicted_labels.append(0)\n",
        "\n",
        "# Extract the corresponding labels from the original dataset using the index of the test data\n",
        "actual_labels = z_test.values\n",
        "\n",
        "# Calculate evaluation metrics based on the predicted labels and the actual labels\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "precision = precision_score(actual_labels, predicted_labels)\n",
        "recall = recall_score(actual_labels, predicted_labels)\n",
        "f1 = f1_score(actual_labels, predicted_labels)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "1UK5nn1ZrLil",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "396f9257-244a-48a0-e071-391992a354fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.2509\n",
            "Recall: 0.9902\n",
            "F1-score: 0.4003\n",
            "Accuracy: 0.2637\n",
            "True Positives (TP): 2212\n",
            "False Positives (FP): 6605\n",
            "True Negatives (TN): 161\n",
            "False Negatives (FN): 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    0.2s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5%"
      ],
      "metadata": {
        "id": "UIVSs9ABl0rQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = df[0]\n",
        "dataset2 = df[1]\n",
        "dataset3 = df[2]\n",
        "dataset4 = df[3]\n",
        "dataset5 = df[4]\n",
        "dataset6 = df[5]\n",
        "dataset7 = df[6]\n",
        "dataset8 = df[7]\n",
        "dataset9 = df[8]\n",
        "\n",
        "dataset1 = dataset1[:50000]\n",
        "dataset2 = dataset2[:50000]\n",
        "dataset3 = dataset3[:50000]\n",
        "dataset4 = dataset4[:50000]\n",
        "dataset5 = dataset5[:50000]\n",
        "dataset6 = dataset6[:50000]\n",
        "dataset7 = dataset7[:50000]\n",
        "dataset8 = dataset8[:50000]\n",
        "dataset9 = dataset9[:50000]\n",
        "\n",
        "print(\"Datasets read successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "483362e3-e85c-4be2-b2ae-2e9016024123",
        "id": "EfrZsNrAl0rY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets read successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN STEP 1 REGRESSOR - RANDOM FOREST"
      ],
      "metadata": {
        "id": "2WxdaQiql0rY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate datasets 1, 2, 3, 4, 5, 7, 8, and 9 for training\n",
        "#train_datasets = [dataset1_sample, dataset2_sample, dataset3_sample, dataset4_sample, dataset5_sample, dataset7_sample, dataset8_sample, dataset9_sample]\n",
        "\n",
        "train_datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9]\n",
        "\n",
        "train_data = pd.concat(train_datasets).reset_index(drop=True)\n",
        "\n",
        "# Separate the training data into features (X) and irregularity data (y)\n",
        "X = train_data.iloc[:, 4:-1]  # Only acceleration data\n",
        "y = train_data[['ALE', 'NLE', 'ALD', 'NLD']]  # Irregularity data\n",
        "z = train_data.iloc[:, -1]\n",
        "\n",
        "# Create the scaler and scale the training features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, z_train, z_test = train_test_split(X_scaled, y, z, test_size=0.1, random_state=42)\n",
        "\n",
        "# Step 1: Train a Random Forest regression model for irregularity prediction\n",
        "irregularity_model = RandomForestRegressor(n_estimators=50, random_state=42, verbose = 2)\n",
        "irregularity_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict irregularity for the training data\n",
        "irregularity_predictions = irregularity_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate evaluation metrics for Step 1\n",
        "mse = mean_squared_error(y_train, irregularity_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_train, irregularity_predictions)\n",
        "r2 = r2_score(y_train, irregularity_predictions)\n",
        "\n",
        "# Print the evaluation metrics for Step 1\n",
        "print(\"Metrics for the RF Regressor - 5%\")\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Step 2: Train an SVC model for damage prediction\n",
        "X_train_combined = np.column_stack((X_train_scaled, irregularity_predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f4b558c-9be2-43bd-f2c4-51bcd9b5ce80",
        "id": "S-si_PQWl0rZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 1 of 50\n",
            "building tree 2 of 50\n",
            "building tree 3 of 50\n",
            "building tree 4 of 50\n",
            "building tree 5 of 50\n",
            "building tree 6 of 50\n",
            "building tree 7 of 50\n",
            "building tree 8 of 50\n",
            "building tree 9 of 50\n",
            "building tree 10 of 50\n",
            "building tree 11 of 50\n",
            "building tree 12 of 50\n",
            "building tree 13 of 50\n",
            "building tree 14 of 50\n",
            "building tree 15 of 50\n",
            "building tree 16 of 50\n",
            "building tree 17 of 50\n",
            "building tree 18 of 50\n",
            "building tree 19 of 50\n",
            "building tree 20 of 50\n",
            "building tree 21 of 50\n",
            "building tree 22 of 50\n",
            "building tree 23 of 50\n",
            "building tree 24 of 50\n",
            "building tree 25 of 50\n",
            "building tree 26 of 50\n",
            "building tree 27 of 50\n",
            "building tree 28 of 50\n",
            "building tree 29 of 50\n",
            "building tree 30 of 50\n",
            "building tree 31 of 50\n",
            "building tree 32 of 50\n",
            "building tree 33 of 50\n",
            "building tree 34 of 50\n",
            "building tree 35 of 50\n",
            "building tree 36 of 50\n",
            "building tree 37 of 50\n",
            "building tree 38 of 50\n",
            "building tree 39 of 50\n",
            "building tree 40 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed: 10.8min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 41 of 50\n",
            "building tree 42 of 50\n",
            "building tree 43 of 50\n",
            "building tree 44 of 50\n",
            "building tree 45 of 50\n",
            "building tree 46 of 50\n",
            "building tree 47 of 50\n",
            "building tree 48 of 50\n",
            "building tree 49 of 50\n",
            "building tree 50 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   18.2s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for the RF Regressor - 5%\n",
            "RMSE: 0.3619960054096055\n",
            "R2: 0.868874327052638\n",
            "MAE: 0.25200585650517593\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = SVC(kernel='rbf')\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labelsp, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THDKzBfWPZtU",
        "outputId": "35965da6-2835-418b-d95a-6ad2d0dec913"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    2.9s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.3551\n",
            "Recall: 0.6650\n",
            "F1-score: 0.4630\n",
            "Accuracy: 0.4730\n",
            "True Positives (TP): 10223\n",
            "False Positives (FP): 18565\n",
            "True Negatives (TN): 11063\n",
            "False Negatives (FN): 5149\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier LightGBM"
      ],
      "metadata": {
        "id": "vqRI7mr_l0rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451d2b20-fa23-4981-b2dc-9e85872b7d95",
        "id": "Lk0r2B6Pl0rZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.3513\n",
            "Recall: 0.6421\n",
            "F1-score: 0.4542\n",
            "Accuracy: 0.4728\n",
            "True Positives (TP): 9870\n",
            "False Positives (FP): 18222\n",
            "True Negatives (TN): 11406\n",
            "False Negatives (FN): 5502\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier NEURAL NETWORK"
      ],
      "metadata": {
        "id": "ll-a1qMvl0rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a neural network model for damage prediction\n",
        "damage_model5 = Sequential()\n",
        "damage_model5.add(Dense(64, activation='relu', input_dim=X_train_combined.shape[1]))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(1, activation='sigmoid'))  # Output neuron for damage classification\n",
        "\n",
        "damage_model5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "damage_model5.fit(X_train_combined, z_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model5.predict(X_test_combined)\n",
        "\n",
        "# Convert damage probabilities to binary predictions using a threshold\n",
        "threshold = 0.5\n",
        "damage_predictions = (damage_predictions > threshold).astype(int)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ea54b4b-a054-447d-ed60-068b84dac418",
        "id": "cHLvtF-ol0rZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "12657/12657 [==============================] - 38s 3ms/step - loss: 0.1549 - accuracy: 0.9337\n",
            "Epoch 2/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.1142 - accuracy: 0.9529\n",
            "Epoch 3/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.1055 - accuracy: 0.9569\n",
            "Epoch 4/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.1005 - accuracy: 0.9588\n",
            "Epoch 5/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.0971 - accuracy: 0.9602\n",
            "Epoch 6/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.0941 - accuracy: 0.9615\n",
            "Epoch 7/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.0921 - accuracy: 0.9621\n",
            "Epoch 8/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.0899 - accuracy: 0.9631\n",
            "Epoch 9/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.0885 - accuracy: 0.9640\n",
            "Epoch 10/10\n",
            "12657/12657 [==============================] - 36s 3ms/step - loss: 0.0873 - accuracy: 0.9642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1407/1407 [==============================] - 2s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.3456\n",
            "Recall: 0.6652\n",
            "F1-score: 0.4549\n",
            "Accuracy: 0.4554\n",
            "True Positives (TP): 10225\n",
            "False Positives (FP): 19360\n",
            "True Negatives (TN): 10268\n",
            "False Negatives (FN): 5147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier XGBoost"
      ],
      "metadata": {
        "id": "Mc8yg-aCl0rZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train an XGBoost classifier for damage prediction\n",
        "damage_model2 = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "damage_model2.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model2.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8e4915e-6a9b-4237-9174-d2fda24f3603",
        "id": "-d_07yVDl0rZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.3500\n",
            "Recall: 0.6672\n",
            "F1-score: 0.4592\n",
            "Accuracy: 0.4631\n",
            "True Positives (TP): 10256\n",
            "False Positives (FP): 19045\n",
            "True Negatives (TN): 10583\n",
            "False Negatives (FN): 5116\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier RANDOM FOREST"
      ],
      "metadata": {
        "id": "O8M9FZhdl0ra"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a Random Forest classifier for damage prediction\n",
        "damage_model6 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "damage_model6.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model6.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8845cf8d-2b8b-4f9f-cee1-a5e2472f6aa7",
        "id": "ZjEiIpjvl0ra"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    1.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.3502\n",
            "Recall: 0.6458\n",
            "F1-score: 0.4541\n",
            "Accuracy: 0.4696\n",
            "True Positives (TP): 9928\n",
            "False Positives (FP): 18422\n",
            "True Negatives (TN): 11206\n",
            "False Negatives (FN): 5444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier Thresholds"
      ],
      "metadata": {
        "id": "ZKqIz82DrXfg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict irregularity for the testing data\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "\n",
        "# Compare the predicted irregularities with a threshold to predict damage\n",
        "threshold_ale = 1.5e-3\n",
        "threshold_nle = 2.3e-3\n",
        "threshold_ald = 1.5e-3\n",
        "threshold_nld = 2.3e-3\n",
        "\n",
        "predicted_labels = []\n",
        "for i in range(len(irregularity_predictions)):\n",
        "    if (irregularity_predictions[i, 0] > threshold_ale) or (irregularity_predictions[i, 1] > threshold_nle) or (irregularity_predictions[i, 2] > threshold_ald) or (irregularity_predictions[i, 3] > threshold_nld):\n",
        "        predicted_labels.append(1)\n",
        "    else:\n",
        "        predicted_labels.append(0)\n",
        "\n",
        "# Extract the corresponding labels from the original dataset using the index of the test data\n",
        "actual_labels = z_test.values\n",
        "\n",
        "# Calculate evaluation metrics based on the predicted labels and the actual labels\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "precision = precision_score(actual_labels, predicted_labels)\n",
        "recall = recall_score(actual_labels, predicted_labels)\n",
        "f1 = f1_score(actual_labels, predicted_labels)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "V3hX4MqjrZae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3923c4f6-de83-48a2-d8be-89c03a5eda68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    2.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.3739\n",
            "Recall: 0.8507\n",
            "F1-score: 0.5195\n",
            "Accuracy: 0.4625\n",
            "True Positives (TP): 13077\n",
            "False Positives (FP): 21893\n",
            "True Negatives (TN): 7735\n",
            "False Negatives (FN): 2295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#25%"
      ],
      "metadata": {
        "id": "czYyeJMpl4wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = df[0]\n",
        "dataset2 = df[1]\n",
        "dataset3 = df[2]\n",
        "dataset4 = df[3]\n",
        "dataset5 = df[4]\n",
        "dataset6 = df[5]\n",
        "dataset7 = df[6]\n",
        "dataset8 = df[7]\n",
        "dataset9 = df[8]\n",
        "\n",
        "dataset1 = dataset1[:250000]\n",
        "dataset2 = dataset2[:250000]\n",
        "dataset3 = dataset3[:250000]\n",
        "dataset4 = dataset4[:250000]\n",
        "dataset5 = dataset5[:250000]\n",
        "dataset6 = dataset6[:250000]\n",
        "dataset7 = dataset7[:250000]\n",
        "dataset8 = dataset8[:250000]\n",
        "dataset9 = dataset9[:250000]\n",
        "\n",
        "print(\"Datasets read successfully\")"
      ],
      "metadata": {
        "id": "roc1zdZPl4wo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "629f2581-8722-44de-969d-ddcbe2de3853"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets read successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN STEP 1 REGRESSOR - RANDOM FOREST"
      ],
      "metadata": {
        "id": "DgllbBsCl4wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate datasets 1, 2, 3, 4, 5, 7, 8, and 9 for training\n",
        "#train_datasets = [dataset1_sample, dataset2_sample, dataset3_sample, dataset4_sample, dataset5_sample, dataset7_sample, dataset8_sample, dataset9_sample]\n",
        "\n",
        "train_datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9]\n",
        "\n",
        "train_data = pd.concat(train_datasets).reset_index(drop=True)\n",
        "\n",
        "# Separate the training data into features (X) and irregularity data (y)\n",
        "X = train_data.iloc[:, 4:-1]  # Only acceleration data\n",
        "y = train_data[['ALE', 'NLE', 'ALD', 'NLD']]  # Irregularity data\n",
        "z = train_data.iloc[:, -1]\n",
        "\n",
        "# Create the scaler and scale the training features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, z_train, z_test = train_test_split(X_scaled, y, z, test_size=0.1, random_state=42)\n",
        "\n",
        "# Step 1: Train a Random Forest regression model for irregularity prediction\n",
        "irregularity_model = RandomForestRegressor(n_estimators=50, random_state=42, verbose = 2)\n",
        "irregularity_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict irregularity for the training data\n",
        "irregularity_predictions = irregularity_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate evaluation metrics for Step 1\n",
        "mse = mean_squared_error(y_train, irregularity_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_train, irregularity_predictions)\n",
        "r2 = r2_score(y_train, irregularity_predictions)\n",
        "\n",
        "# Print the evaluation metrics for Step 1\n",
        "print(\"Metrics for the RF Regressor - 25%\")\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Step 2: Train an SVC model for damage prediction\n",
        "X_train_combined = np.column_stack((X_train_scaled, irregularity_predictions))"
      ],
      "metadata": {
        "id": "M0VQTCssl4wp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "643e877b-874e-4f8b-a4a7-f52eac7611d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 1 of 50\n",
            "building tree 2 of 50\n",
            "building tree 3 of 50\n",
            "building tree 4 of 50\n",
            "building tree 5 of 50\n",
            "building tree 6 of 50\n",
            "building tree 7 of 50\n",
            "building tree 8 of 50\n",
            "building tree 9 of 50\n",
            "building tree 10 of 50\n",
            "building tree 11 of 50\n",
            "building tree 12 of 50\n",
            "building tree 13 of 50\n",
            "building tree 14 of 50\n",
            "building tree 15 of 50\n",
            "building tree 16 of 50\n",
            "building tree 17 of 50\n",
            "building tree 18 of 50\n",
            "building tree 19 of 50\n",
            "building tree 20 of 50\n",
            "building tree 21 of 50\n",
            "building tree 22 of 50\n",
            "building tree 23 of 50\n",
            "building tree 24 of 50\n",
            "building tree 25 of 50\n",
            "building tree 26 of 50\n",
            "building tree 27 of 50\n",
            "building tree 28 of 50\n",
            "building tree 29 of 50\n",
            "building tree 30 of 50\n",
            "building tree 31 of 50\n",
            "building tree 32 of 50\n",
            "building tree 33 of 50\n",
            "building tree 34 of 50\n",
            "building tree 35 of 50\n",
            "building tree 36 of 50\n",
            "building tree 37 of 50\n",
            "building tree 38 of 50\n",
            "building tree 39 of 50\n",
            "building tree 40 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed: 40.9min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 41 of 50\n",
            "building tree 42 of 50\n",
            "building tree 43 of 50\n",
            "building tree 44 of 50\n",
            "building tree 45 of 50\n",
            "building tree 46 of 50\n",
            "building tree 47 of 50\n",
            "building tree 48 of 50\n",
            "building tree 49 of 50\n",
            "building tree 50 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:  1.4min\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for the RF Regressor - 25%\n",
            "RMSE: 0.36502539569886366\n",
            "R2: 0.8667350321786691\n",
            "MAE: 0.26980613835494294\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier LightGBM"
      ],
      "metadata": {
        "id": "mjmBSkxHl4wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "iTLFKx2Tl4wp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aeef375-70ed-448f-83bc-2b3428f1b8d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:    9.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.4253\n",
            "Recall: 0.5913\n",
            "F1-score: 0.4948\n",
            "Accuracy: 0.5137\n",
            "True Positives (TP): 53579\n",
            "False Positives (FP): 72393\n",
            "True Negatives (TN): 61993\n",
            "False Negatives (FN): 37035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier NEURAL NETWORK"
      ],
      "metadata": {
        "id": "nA1kBjEil4wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a neural network model for damage prediction\n",
        "damage_model5 = Sequential()\n",
        "damage_model5.add(Dense(64, activation='relu', input_dim=X_train_combined.shape[1]))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(1, activation='sigmoid'))  # Output neuron for damage classification\n",
        "\n",
        "damage_model5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "damage_model5.fit(X_train_combined, z_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model5.predict(X_test_combined)\n",
        "\n",
        "# Convert damage probabilities to binary predictions using a threshold\n",
        "threshold = 0.5\n",
        "damage_predictions = (damage_predictions > threshold).astype(int)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "Es4ccEqyl4wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5b2b70-e73b-4fc2-aa18-818edaf0e551"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "63282/63282 [==============================] - 185s 3ms/step - loss: 0.1448 - accuracy: 0.9376\n",
            "Epoch 2/10\n",
            "63282/63282 [==============================] - 183s 3ms/step - loss: 0.1211 - accuracy: 0.9484\n",
            "Epoch 3/10\n",
            "63282/63282 [==============================] - 184s 3ms/step - loss: 0.1155 - accuracy: 0.9510\n",
            "Epoch 4/10\n",
            "63282/63282 [==============================] - 189s 3ms/step - loss: 0.1125 - accuracy: 0.9525\n",
            "Epoch 5/10\n",
            "63282/63282 [==============================] - 192s 3ms/step - loss: 0.1104 - accuracy: 0.9534\n",
            "Epoch 6/10\n",
            "63282/63282 [==============================] - 193s 3ms/step - loss: 0.1088 - accuracy: 0.9542\n",
            "Epoch 7/10\n",
            "63282/63282 [==============================] - 190s 3ms/step - loss: 0.1075 - accuracy: 0.9548\n",
            "Epoch 8/10\n",
            "63282/63282 [==============================] - 192s 3ms/step - loss: 0.1065 - accuracy: 0.9552\n",
            "Epoch 9/10\n",
            "63282/63282 [==============================] - 192s 3ms/step - loss: 0.1058 - accuracy: 0.9555\n",
            "Epoch 10/10\n",
            "63282/63282 [==============================] - 192s 3ms/step - loss: 0.1052 - accuracy: 0.9557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   10.7s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7032/7032 [==============================] - 9s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4162\n",
            "Recall: 0.6261\n",
            "F1-score: 0.5000\n",
            "Accuracy: 0.4958\n",
            "True Positives (TP): 56730\n",
            "False Positives (FP): 79564\n",
            "True Negatives (TN): 54822\n",
            "False Negatives (FN): 33884\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier XGBoost"
      ],
      "metadata": {
        "id": "KeKv41kel4wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train an XGBoost classifier for damage prediction\n",
        "damage_model2 = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "damage_model2.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model2.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "pd2l4FSNl4wq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "505de851-6bad-4b7e-cf6f-ef0dc6d15c67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   10.6s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.4235\n",
            "Recall: 0.5898\n",
            "F1-score: 0.4930\n",
            "Accuracy: 0.5114\n",
            "True Positives (TP): 53447\n",
            "False Positives (FP): 72762\n",
            "True Negatives (TN): 61624\n",
            "False Negatives (FN): 37167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier RANDOM FOREST"
      ],
      "metadata": {
        "id": "_M9ALVp1l4wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a Random Forest classifier for damage prediction\n",
        "damage_model6 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "damage_model6.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model6.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "Kv-6iUMNl4wr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd91348-215f-4218-f9f3-271e3fc97229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   10.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.4219\n",
            "Recall: 0.5953\n",
            "F1-score: 0.4938\n",
            "Accuracy: 0.5085\n",
            "True Positives (TP): 53942\n",
            "False Positives (FP): 73917\n",
            "True Negatives (TN): 60469\n",
            "False Negatives (FN): 36672\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier Thresholds"
      ],
      "metadata": {
        "id": "pWFkWkXarcKN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict irregularity for the testing data\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "\n",
        "# Compare the predicted irregularities with a threshold to predict damage\n",
        "threshold_ale = 1.5e-3\n",
        "threshold_nle = 2.3e-3\n",
        "threshold_ald = 1.5e-3\n",
        "threshold_nld = 2.3e-3\n",
        "\n",
        "predicted_labels = []\n",
        "for i in range(len(irregularity_predictions)):\n",
        "    if (irregularity_predictions[i, 0] > threshold_ale) or (irregularity_predictions[i, 1] > threshold_nle) or (irregularity_predictions[i, 2] > threshold_ald) or (irregularity_predictions[i, 3] > threshold_nld):\n",
        "        predicted_labels.append(1)\n",
        "    else:\n",
        "        predicted_labels.append(0)\n",
        "\n",
        "# Extract the corresponding labels from the original dataset using the index of the test data\n",
        "actual_labels = z_test.values\n",
        "\n",
        "# Calculate evaluation metrics based on the predicted labels and the actual labels\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "precision = precision_score(actual_labels, predicted_labels)\n",
        "recall = recall_score(actual_labels, predicted_labels)\n",
        "f1 = f1_score(actual_labels, predicted_labels)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "20DdhFstrdt0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75bb9ee9-e57a-487d-e5a7-4437bb1abfb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done  40 tasks      | elapsed:   10.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.4426\n",
            "Recall: 0.8338\n",
            "F1-score: 0.5782\n",
            "Accuracy: 0.5101\n",
            "True Positives (TP): 75551\n",
            "False Positives (FP): 95156\n",
            "True Negatives (TN): 39230\n",
            "False Negatives (FN): 15063\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#100%"
      ],
      "metadata": {
        "id": "r_gP4q_Ll7_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset1 = df[0]\n",
        "dataset2 = df[1]\n",
        "dataset3 = df[2]\n",
        "dataset4 = df[3]\n",
        "dataset5 = df[4]\n",
        "dataset6 = df[5]\n",
        "dataset7 = df[6]\n",
        "dataset8 = df[7]\n",
        "dataset9 = df[8]\n",
        "\n",
        "dataset1 = dataset1[:1000000]\n",
        "dataset2 = dataset2[:1000000]\n",
        "dataset3 = dataset3[:1000000]\n",
        "dataset4 = dataset4[:1000000]\n",
        "dataset5 = dataset5[:1000000]\n",
        "dataset6 = dataset6[:1000000]\n",
        "dataset7 = dataset7[:1000000]\n",
        "dataset8 = dataset8[:1000000]\n",
        "dataset9 = dataset9[:1000000]\n",
        "\n",
        "print(\"Datasets read successfully\")"
      ],
      "metadata": {
        "id": "s-Nko-Szl7_l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148a6e01-ed57-4dd3-c0ed-b60e9d9382f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets read successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TRAIN STEP 1 REGRESSOR - RANDOM FOREST"
      ],
      "metadata": {
        "id": "Q3HRfoETl7_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate datasets 1, 2, 3, 4, 5, 7, 8, and 9 for training\n",
        "#train_datasets = [dataset1_sample, dataset2_sample, dataset3_sample, dataset4_sample, dataset5_sample, dataset7_sample, dataset8_sample, dataset9_sample]\n",
        "\n",
        "train_datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9]\n",
        "\n",
        "train_data = pd.concat(train_datasets).reset_index(drop=True)\n",
        "\n",
        "# Separate the training data into features (X) and irregularity data (y)\n",
        "X = train_data.iloc[:, 4:-1]  # Only acceleration data\n",
        "y = train_data[['ALE', 'NLE', 'ALD', 'NLD']]  # Irregularity data\n",
        "z = train_data.iloc[:, -1]\n",
        "\n",
        "# Create the scaler and scale the training features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, z_train, z_test = train_test_split(X_scaled, y, z, test_size=0.1, random_state=42)\n",
        "\n",
        "# Step 1: Train a Random Forest regression model for irregularity prediction\n",
        "irregularity_model = RandomForestRegressor(n_estimators=30, random_state=42, verbose = 2)\n",
        "irregularity_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict irregularity for the training data\n",
        "irregularity_predictions = irregularity_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate evaluation metrics for Step 1\n",
        "mse = mean_squared_error(y_train, irregularity_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_train, irregularity_predictions)\n",
        "r2 = r2_score(y_train, irregularity_predictions)\n",
        "\n",
        "# Print the evaluation metrics for Step 1\n",
        "print(\"Metrics for the RF Regressor - 100%\")\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Step 2: Train an SVC model for damage prediction\n",
        "X_train_combined = np.column_stack((X_train_scaled, irregularity_predictions))"
      ],
      "metadata": {
        "id": "zfiLTNFCl7_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75961630-a84c-4a35-b21f-c789f26df5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "building tree 1 of 30\n",
            "building tree 2 of 30\n",
            "building tree 3 of 30\n",
            "building tree 4 of 30\n",
            "building tree 5 of 30\n",
            "building tree 6 of 30\n",
            "building tree 7 of 30\n",
            "building tree 8 of 30\n",
            "building tree 9 of 30\n",
            "building tree 10 of 30\n",
            "building tree 11 of 30\n",
            "building tree 12 of 30\n",
            "building tree 13 of 30\n",
            "building tree 14 of 30\n",
            "building tree 15 of 30\n",
            "building tree 16 of 30\n",
            "building tree 17 of 30\n",
            "building tree 18 of 30\n",
            "building tree 19 of 30\n",
            "building tree 20 of 30\n",
            "building tree 21 of 30\n",
            "building tree 22 of 30\n",
            "building tree 23 of 30\n",
            "building tree 24 of 30\n",
            "building tree 25 of 30\n",
            "building tree 26 of 30\n",
            "building tree 27 of 30\n",
            "building tree 28 of 30\n",
            "building tree 29 of 30\n",
            "building tree 30 of 30\n",
            "Metrics for the RF Regressor - 100%\n",
            "RMSE: 0.3731724398604293\n",
            "R2: 0.8607334116267602\n",
            "MAE: 0.2856319892912499\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier LightGBM"
      ],
      "metadata": {
        "id": "ch6eMckVl7_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "XUkYhP3Pl7_m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef655912-6aae-44f4-918e-81791de79ba4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.4443\n",
            "Recall: 0.4402\n",
            "F1-score: 0.4422\n",
            "Accuracy: 0.5466\n",
            "True Positives (TP): 161761\n",
            "False Positives (FP): 202354\n",
            "True Negatives (TN): 330143\n",
            "False Negatives (FN): 205742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier NEURAL NETWORK"
      ],
      "metadata": {
        "id": "MWY4emN9l7_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a neural network model for damage prediction\n",
        "damage_model5 = Sequential()\n",
        "damage_model5.add(Dense(64, activation='relu', input_dim=X_train_combined.shape[1]))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(1, activation='sigmoid'))  # Output neuron for damage classification\n",
        "\n",
        "damage_model5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "damage_model5.fit(X_train_combined, z_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model5.predict(X_test_combined)\n",
        "\n",
        "# Convert damage probabilities to binary predictions using a threshold\n",
        "threshold = 0.5\n",
        "damage_predictions = (damage_predictions > threshold).astype(int)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "q_1gSLUel7_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de0a83d-e91a-4888-ede7-e1ed80b0d38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "253125/253125 [==============================] - 378s 1ms/step - loss: 0.1552 - accuracy: 0.9319\n",
            "Epoch 2/10\n",
            "253125/253125 [==============================] - 374s 1ms/step - loss: 0.1423 - accuracy: 0.9383\n",
            "Epoch 3/10\n",
            "253125/253125 [==============================] - 374s 1ms/step - loss: 0.1396 - accuracy: 0.9396\n",
            "Epoch 4/10\n",
            "253125/253125 [==============================] - 370s 1ms/step - loss: 0.1385 - accuracy: 0.9403\n",
            "Epoch 5/10\n",
            "253125/253125 [==============================] - 370s 1ms/step - loss: 0.1378 - accuracy: 0.9407\n",
            "Epoch 6/10\n",
            "253125/253125 [==============================] - 369s 1ms/step - loss: 0.1374 - accuracy: 0.9410\n",
            "Epoch 7/10\n",
            "253125/253125 [==============================] - 368s 1ms/step - loss: 0.1372 - accuracy: 0.9411\n",
            "Epoch 8/10\n",
            "253125/253125 [==============================] - 364s 1ms/step - loss: 0.1373 - accuracy: 0.9413\n",
            "Epoch 9/10\n",
            "253125/253125 [==============================] - 365s 1ms/step - loss: 0.1385 - accuracy: 0.9411\n",
            "Epoch 10/10\n",
            "253125/253125 [==============================] - 366s 1ms/step - loss: 0.1377 - accuracy: 0.9413\n",
            "28125/28125 [==============================] - 28s 980us/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4300\n",
            "Recall: 0.4384\n",
            "F1-score: 0.4342\n",
            "Accuracy: 0.5334\n",
            "True Positives (TP): 161112\n",
            "False Positives (FP): 213534\n",
            "True Negatives (TN): 318963\n",
            "False Negatives (FN): 206391\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier XGBoost"
      ],
      "metadata": {
        "id": "cYNOT2d6l7_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train an XGBoost classifier for damage prediction\n",
        "damage_model2 = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "damage_model2.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model2.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "-FscBMT6l7_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f10aa230-7c99-4cee-ea83-db2049e2d7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.4394\n",
            "Recall: 0.4452\n",
            "F1-score: 0.4423\n",
            "Accuracy: 0.5415\n",
            "True Positives (TP): 163622\n",
            "False Positives (FP): 208740\n",
            "True Negatives (TN): 323757\n",
            "False Negatives (FN): 203881\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier RANDOM FOREST"
      ],
      "metadata": {
        "id": "EuaRZxWql7_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Train a Random Forest classifier for damage prediction\n",
        "damage_model6 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "damage_model6.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model6.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "QAgMgFNgl7_o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af2825aa-2350-4d85-d0a1-f1adc5917876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.4404\n",
            "Recall: 0.4491\n",
            "F1-score: 0.4447\n",
            "Accuracy: 0.5420\n",
            "True Positives (TP): 165033\n",
            "False Positives (FP): 209692\n",
            "True Negatives (TN): 322805\n",
            "False Negatives (FN): 202470\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classifier Thresholds"
      ],
      "metadata": {
        "id": "jqm1d0PyrfkU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict irregularity for the testing data\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "\n",
        "# Compare the predicted irregularities with a threshold to predict damage\n",
        "threshold_ale = 1.5e-3\n",
        "threshold_nle = 2.3e-3\n",
        "threshold_ald = 1.5e-3\n",
        "threshold_nld = 2.3e-3\n",
        "\n",
        "predicted_labels = []\n",
        "for i in range(len(irregularity_predictions)):\n",
        "    if (irregularity_predictions[i, 0] > threshold_ale) or (irregularity_predictions[i, 1] > threshold_nle) or (irregularity_predictions[i, 2] > threshold_ald) or (irregularity_predictions[i, 3] > threshold_nld):\n",
        "        predicted_labels.append(1)\n",
        "    else:\n",
        "        predicted_labels.append(0)\n",
        "\n",
        "# Extract the corresponding labels from the original dataset using the index of the test data\n",
        "actual_labels = z_test.values\n",
        "\n",
        "# Calculate evaluation metrics based on the predicted labels and the actual labels\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "precision = precision_score(actual_labels, predicted_labels)\n",
        "recall = recall_score(actual_labels, predicted_labels)\n",
        "f1 = f1_score(actual_labels, predicted_labels)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ],
      "metadata": {
        "id": "WoZ3eJVarg61",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "397315d8-7506-4faa-ca2b-d7ce497466b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Metrics:\n",
            "Precision: 0.4581\n",
            "Recall: 0.8168\n",
            "F1-score: 0.5870\n",
            "Accuracy: 0.5307\n",
            "True Positives (TP): 300160\n",
            "False Positives (FP): 355029\n",
            "True Negatives (TN): 177468\n",
            "False Negatives (FN): 67343\n"
          ]
        }
      ]
    }
  ]
}