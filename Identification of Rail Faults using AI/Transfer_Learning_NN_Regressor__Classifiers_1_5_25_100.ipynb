{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjV763VvWzM6"
      },
      "source": [
        "# ALL IMPORTS NECESSARY ARE HERE AT THE TOP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg4Fs_FogHv4",
        "outputId": "00c67209-b0de-4263-acb0-e5354d05b2ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.3.25)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow)\n",
            "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.7.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.40.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow) (1.11.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow) (3.2.2)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.1\n",
            "    Uninstalling numpy-1.25.1:\n",
            "      Successfully uninstalled numpy-1.25.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "chex 0.1.7 requires jax>=0.4.6, but you have jax 0.3.25 which is incompatible.\n",
            "flax 0.7.0 requires jax>=0.4.2, but you have jax 0.3.25 which is incompatible.\n",
            "orbax-checkpoint 0.2.7 requires jax>=0.4.9, but you have jax 0.3.25 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.23.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "from sklearn.svm import SVC, SVR\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, f1_score, mean_absolute_error, mean_squared_error, r2_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits import mplot3d\n",
        "from google.colab import drive\n",
        "from scipy.interpolate import interp1d\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "!pip install tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4MVQGQdOcj7"
      },
      "source": [
        "https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall?hl=pt-br"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9tdARqgRwye-",
        "outputId": "315d583c-3a19-4fb3-8851-0f66570df031"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RdcD4TOW3aO"
      },
      "source": [
        "# READING THE DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aL1igPK3sOny",
        "outputId": "8dcdcadb-d128-4d1f-f658-5b697493e0e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario1.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario2.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario3.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario4.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario5.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario6.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario7.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario8.mat\n",
            "Reading File: /content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario9.mat\n"
          ]
        }
      ],
      "source": [
        "file_paths = [\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario1.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario2.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario3.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario4.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario5.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario6.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario7.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario8.mat',\n",
        "    '/content/drive/MyDrive/Tese_Dados/Final_Data/final_data_damaged_scenario9.mat'\n",
        "]\n",
        "\n",
        "file_data = []\n",
        "df = []\n",
        "\n",
        "for i, file_path in enumerate(file_paths):\n",
        "    print(f\"Reading File: {file_path}\")\n",
        "    data = sio.loadmat(file_path)\n",
        "    df.append(pd.DataFrame(data['data'], columns=['ALE', 'NLE', 'ALD', 'NLD','S4_y1', 'S4_z1', 'S1_y1', 'S1_z1', 'S2_y1', 'S2_z1', 'S3_y1', 'S3_z1', 'Label']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-9d0bCGsZ-N"
      },
      "source": [
        "#NN Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4f8IPmNsjin"
      },
      "source": [
        "#1%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLVp2A91sjiu",
        "outputId": "b0f50131-fc9c-4eea-a2e5-7dafd762577f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets read successfully\n"
          ]
        }
      ],
      "source": [
        "dataset1 = df[0]\n",
        "dataset2 = df[1]\n",
        "dataset3 = df[2]\n",
        "dataset4 = df[3]\n",
        "dataset5 = df[4]\n",
        "dataset6 = df[5]\n",
        "dataset7 = df[6]\n",
        "dataset8 = df[7]\n",
        "dataset9 = df[8]\n",
        "\n",
        "dataset1 = dataset1[:10000]\n",
        "dataset2 = dataset2[:10000]\n",
        "dataset3 = dataset3[:10000]\n",
        "dataset4 = dataset4[:10000]\n",
        "dataset5 = dataset5[:10000]\n",
        "dataset6 = dataset6[:10000]\n",
        "dataset7 = dataset7[:10000]\n",
        "dataset8 = dataset8[:10000]\n",
        "dataset9 = dataset9[:10000]\n",
        "\n",
        "print(\"Datasets read successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTTcWWv-sjiv"
      },
      "source": [
        "TRAIN STEP 1 REGRESSOR - Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_Vq8fQlsjiv",
        "outputId": "378d0b43-3524-4a51-f820-28f8e1594d5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "2532/2532 [==============================] - 22s 5ms/step - loss: 0.8878 - accuracy: 0.3169\n",
            "Epoch 2/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.8568 - accuracy: 0.3388\n",
            "Epoch 3/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.8165 - accuracy: 0.3635\n",
            "Epoch 4/50\n",
            "2532/2532 [==============================] - 15s 6ms/step - loss: 0.7980 - accuracy: 0.3861\n",
            "Epoch 5/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7875 - accuracy: 0.3939\n",
            "Epoch 6/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7743 - accuracy: 0.3987\n",
            "Epoch 7/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7653 - accuracy: 0.4075\n",
            "Epoch 8/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7574 - accuracy: 0.4126\n",
            "Epoch 9/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7530 - accuracy: 0.4169\n",
            "Epoch 10/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7499 - accuracy: 0.4219\n",
            "Epoch 11/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7437 - accuracy: 0.4223\n",
            "Epoch 12/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7398 - accuracy: 0.4264\n",
            "Epoch 13/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7368 - accuracy: 0.4263\n",
            "Epoch 14/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7327 - accuracy: 0.4312\n",
            "Epoch 15/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7286 - accuracy: 0.4360\n",
            "Epoch 16/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7261 - accuracy: 0.4322\n",
            "Epoch 17/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7230 - accuracy: 0.4340\n",
            "Epoch 18/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7210 - accuracy: 0.4388\n",
            "Epoch 19/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7175 - accuracy: 0.4454\n",
            "Epoch 20/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7158 - accuracy: 0.4432\n",
            "Epoch 21/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7129 - accuracy: 0.4444\n",
            "Epoch 22/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7081 - accuracy: 0.4494\n",
            "Epoch 23/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7064 - accuracy: 0.4502\n",
            "Epoch 24/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7054 - accuracy: 0.4539\n",
            "Epoch 25/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.7015 - accuracy: 0.4555\n",
            "Epoch 26/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6999 - accuracy: 0.4514\n",
            "Epoch 27/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6978 - accuracy: 0.4587\n",
            "Epoch 28/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6937 - accuracy: 0.4562\n",
            "Epoch 29/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6922 - accuracy: 0.4593\n",
            "Epoch 30/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6931 - accuracy: 0.4614\n",
            "Epoch 31/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6901 - accuracy: 0.4598\n",
            "Epoch 32/50\n",
            "2532/2532 [==============================] - 12s 5ms/step - loss: 0.6869 - accuracy: 0.4564\n",
            "Epoch 33/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6864 - accuracy: 0.4602\n",
            "Epoch 34/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6841 - accuracy: 0.4597\n",
            "Epoch 35/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6823 - accuracy: 0.4626\n",
            "Epoch 36/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6809 - accuracy: 0.4656\n",
            "Epoch 37/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6796 - accuracy: 0.4694\n",
            "Epoch 38/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6796 - accuracy: 0.4697\n",
            "Epoch 39/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6759 - accuracy: 0.4672\n",
            "Epoch 40/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6733 - accuracy: 0.4712\n",
            "Epoch 41/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6728 - accuracy: 0.4672\n",
            "Epoch 42/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6719 - accuracy: 0.4727\n",
            "Epoch 43/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6694 - accuracy: 0.4694\n",
            "Epoch 44/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6661 - accuracy: 0.4687\n",
            "Epoch 45/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6647 - accuracy: 0.4713\n",
            "Epoch 46/50\n",
            "2532/2532 [==============================] - 14s 5ms/step - loss: 0.6645 - accuracy: 0.4709\n",
            "Epoch 47/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6668 - accuracy: 0.4699\n",
            "Epoch 48/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6611 - accuracy: 0.4757\n",
            "Epoch 49/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6608 - accuracy: 0.4775\n",
            "Epoch 50/50\n",
            "2532/2532 [==============================] - 13s 5ms/step - loss: 0.6625 - accuracy: 0.4729\n",
            "2532/2532 [==============================] - 4s 2ms/step\n",
            "Metrics for the RF Regressor - 1%\n",
            "RMSE: 0.812131110944112\n",
            "R2: 0.3398646648697943\n",
            "MAE: 0.5378062363124518\n"
          ]
        }
      ],
      "source": [
        "# Concatenate datasets 1, 2, 3, 4, 5, 7, 8, and 9 for training\n",
        "#train_datasets = [dataset1_sample, dataset2_sample, dataset3_sample, dataset4_sample, dataset5_sample, dataset7_sample, dataset8_sample, dataset9_sample]\n",
        "\n",
        "train_datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9]\n",
        "\n",
        "train_data = pd.concat(train_datasets).reset_index(drop=True)\n",
        "\n",
        "# Separate the training data into features (X) and irregularity data (y)\n",
        "X = train_data.iloc[:, 4:-1]  # Only acceleration data\n",
        "y = train_data[['ALE', 'NLE', 'ALD', 'NLD']]  # Irregularity data\n",
        "z = train_data.iloc[:, -1]\n",
        "\n",
        "# Create the scaler and scale the training features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, z_train, z_test = train_test_split(X_scaled, y, z, test_size=0.1, random_state=42)\n",
        "\n",
        "# Step 1: Train a neural network model for irregularity prediction\n",
        "irregularity_model = Sequential()\n",
        "irregularity_model.add(Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(4))  # 4 output neurons for irregularity columns\n",
        "\n",
        "irregularity_model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "irregularity_model.fit(X_train_scaled, y_train, epochs=50)\n",
        "\n",
        "# Predict irregularity for the training data\n",
        "irregularity_predictions = irregularity_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate evaluation metrics for Step 1\n",
        "mse = mean_squared_error(y_train, irregularity_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_train, irregularity_predictions)\n",
        "r2 = r2_score(y_train, irregularity_predictions)\n",
        "\n",
        "# Print the evaluation metrics for Step 1\n",
        "print(\"Metrics for the RF Regressor - 1%\")\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "X_train_combined = np.column_stack((X_train_scaled, irregularity_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gahQ8aIcsjiv"
      },
      "source": [
        "Classifier LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cbo_EHv1sjiv",
        "outputId": "c15d65fc-c43d-4169-eade-40e881bac16b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "282/282 [==============================] - 0s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.2769\n",
            "Recall: 0.2981\n",
            "F1-score: 0.2871\n",
            "Accuracy: 0.6326\n",
            "True Positives (TP): 666\n",
            "False Positives (FP): 1739\n",
            "True Negatives (TN): 5027\n",
            "False Negatives (FN): 1568\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1B_NU-5fsjiv"
      },
      "source": [
        "Classifier NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yx23YE1Esjiw",
        "outputId": "7803780b-046f-417f-d517-10530642fcd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2532/2532 [==============================] - 10s 3ms/step - loss: 0.4586 - accuracy: 0.7911\n",
            "Epoch 2/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4495 - accuracy: 0.7957\n",
            "Epoch 3/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4464 - accuracy: 0.7981\n",
            "Epoch 4/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4440 - accuracy: 0.7989\n",
            "Epoch 5/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4419 - accuracy: 0.8004\n",
            "Epoch 6/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4404 - accuracy: 0.8015\n",
            "Epoch 7/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4390 - accuracy: 0.8016\n",
            "Epoch 8/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4374 - accuracy: 0.8025\n",
            "Epoch 9/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4359 - accuracy: 0.8038\n",
            "Epoch 10/10\n",
            "2532/2532 [==============================] - 8s 3ms/step - loss: 0.4347 - accuracy: 0.8044\n",
            "282/282 [==============================] - 0s 2ms/step\n",
            "282/282 [==============================] - 0s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.2899\n",
            "Recall: 0.3026\n",
            "F1-score: 0.2961\n",
            "Accuracy: 0.6429\n",
            "True Positives (TP): 676\n",
            "False Positives (FP): 1656\n",
            "True Negatives (TN): 5110\n",
            "False Negatives (FN): 1558\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a neural network model for damage prediction\n",
        "damage_model5 = Sequential()\n",
        "damage_model5.add(Dense(64, activation='relu', input_dim=X_train_combined.shape[1]))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(1, activation='sigmoid'))  # Output neuron for damage classification\n",
        "\n",
        "damage_model5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "damage_model5.fit(X_train_combined, z_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model5.predict(X_test_combined)\n",
        "\n",
        "# Convert damage probabilities to binary predictions using a threshold\n",
        "threshold = 0.5\n",
        "damage_predictions = (damage_predictions > threshold).astype(int)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELW4S_nqsjiw"
      },
      "source": [
        "Classifier XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ81RjAysjiw",
        "outputId": "835b92a1-dc0e-43c2-e764-60e5a8258ad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "282/282 [==============================] - 0s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.2855\n",
            "Recall: 0.3227\n",
            "F1-score: 0.3030\n",
            "Accuracy: 0.6314\n",
            "True Positives (TP): 721\n",
            "False Positives (FP): 1804\n",
            "True Negatives (TN): 4962\n",
            "False Negatives (FN): 1513\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train an XGBoost classifier for damage prediction\n",
        "damage_model2 = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "damage_model2.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model2.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaT-aHmOsjiw"
      },
      "source": [
        "Classifier RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-DtIvbMDsjiw",
        "outputId": "a43cf9a7-d98f-42fd-e7fd-59dff3c03fb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "282/282 [==============================] - 1s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.2896\n",
            "Recall: 0.2153\n",
            "F1-score: 0.2470\n",
            "Accuracy: 0.6741\n",
            "True Positives (TP): 481\n",
            "False Positives (FP): 1180\n",
            "True Negatives (TN): 5586\n",
            "False Negatives (FN): 1753\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a Random Forest classifier for damage prediction\n",
        "damage_model6 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "damage_model6.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model6.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFRh2HpYsjix"
      },
      "source": [
        "Classifier Thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHSpxViHsjix",
        "outputId": "f318c1ab-223d-48bc-a428-e714e68d91e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "282/282 [==============================] - 1s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.2482\n",
            "Recall: 1.0000\n",
            "F1-score: 0.3977\n",
            "Accuracy: 0.2482\n",
            "True Positives (TP): 2234\n",
            "False Positives (FP): 6766\n",
            "True Negatives (TN): 0\n",
            "False Negatives (FN): 0\n"
          ]
        }
      ],
      "source": [
        "# Predict irregularity for the testing data\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "\n",
        "# Compare the predicted irregularities with a threshold to predict damage\n",
        "threshold_ale = 1.5e-3\n",
        "threshold_nle = 2.3e-3\n",
        "threshold_ald = 1.5e-3\n",
        "threshold_nld = 2.3e-3\n",
        "\n",
        "predicted_labels = []\n",
        "for i in range(len(irregularity_predictions)):\n",
        "    if (irregularity_predictions[i, 0] > threshold_ale) or (irregularity_predictions[i, 1] > threshold_nle) or (irregularity_predictions[i, 2] > threshold_ald) or (irregularity_predictions[i, 3] > threshold_nld):\n",
        "        predicted_labels.append(1)\n",
        "    else:\n",
        "        predicted_labels.append(0)\n",
        "\n",
        "# Extract the corresponding labels from the original dataset using the index of the test data\n",
        "actual_labels = z_test.values\n",
        "\n",
        "# Calculate evaluation metrics based on the predicted labels and the actual labels\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "precision = precision_score(actual_labels, predicted_labels)\n",
        "recall = recall_score(actual_labels, predicted_labels)\n",
        "f1 = f1_score(actual_labels, predicted_labels)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9oOkXtXsjix"
      },
      "source": [
        "#5%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWzKRX5Vsjix",
        "outputId": "39a19527-b141-4919-9e65-09271c083340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets read successfully\n"
          ]
        }
      ],
      "source": [
        "dataset1 = df[0]\n",
        "dataset2 = df[1]\n",
        "dataset3 = df[2]\n",
        "dataset4 = df[3]\n",
        "dataset5 = df[4]\n",
        "dataset6 = df[5]\n",
        "dataset7 = df[6]\n",
        "dataset8 = df[7]\n",
        "dataset9 = df[8]\n",
        "\n",
        "dataset1 = dataset1[:50000]\n",
        "dataset2 = dataset2[:50000]\n",
        "dataset3 = dataset3[:50000]\n",
        "dataset4 = dataset4[:50000]\n",
        "dataset5 = dataset5[:50000]\n",
        "dataset6 = dataset6[:50000]\n",
        "dataset7 = dataset7[:50000]\n",
        "dataset8 = dataset8[:50000]\n",
        "dataset9 = dataset9[:50000]\n",
        "\n",
        "print(\"Datasets read successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uKCua8msjix"
      },
      "source": [
        "TRAIN STEP 1 REGRESSOR - RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SvzMT4bsjiy",
        "outputId": "d7d3fcdd-6457-4cae-f2b6-ca952ccea826"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12657/12657 [==============================] - 72s 5ms/step - loss: 0.9426 - accuracy: 0.2842\n",
            "Epoch 2/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.9303 - accuracy: 0.2867\n",
            "Epoch 3/50\n",
            "12657/12657 [==============================] - 71s 6ms/step - loss: 0.9219 - accuracy: 0.2883\n",
            "Epoch 4/50\n",
            "12657/12657 [==============================] - 67s 5ms/step - loss: 0.9151 - accuracy: 0.2891\n",
            "Epoch 5/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.9099 - accuracy: 0.2916\n",
            "Epoch 6/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.9060 - accuracy: 0.2918\n",
            "Epoch 7/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.9016 - accuracy: 0.2925\n",
            "Epoch 8/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8983 - accuracy: 0.2930\n",
            "Epoch 9/50\n",
            "12657/12657 [==============================] - 67s 5ms/step - loss: 0.8939 - accuracy: 0.2964\n",
            "Epoch 10/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8895 - accuracy: 0.2984\n",
            "Epoch 11/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8863 - accuracy: 0.2990\n",
            "Epoch 12/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8838 - accuracy: 0.3005\n",
            "Epoch 13/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8814 - accuracy: 0.3019\n",
            "Epoch 14/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8797 - accuracy: 0.3023\n",
            "Epoch 15/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8782 - accuracy: 0.3024\n",
            "Epoch 16/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8771 - accuracy: 0.3038\n",
            "Epoch 17/50\n",
            "12657/12657 [==============================] - 71s 6ms/step - loss: 0.8752 - accuracy: 0.3043\n",
            "Epoch 18/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8743 - accuracy: 0.3059\n",
            "Epoch 19/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8729 - accuracy: 0.3071\n",
            "Epoch 20/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8717 - accuracy: 0.3062\n",
            "Epoch 21/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8714 - accuracy: 0.3069\n",
            "Epoch 22/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8712 - accuracy: 0.3063\n",
            "Epoch 23/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8694 - accuracy: 0.3097\n",
            "Epoch 24/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8689 - accuracy: 0.3088\n",
            "Epoch 25/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8683 - accuracy: 0.3088\n",
            "Epoch 26/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8679 - accuracy: 0.3083\n",
            "Epoch 27/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8660 - accuracy: 0.3087\n",
            "Epoch 28/50\n",
            "12657/12657 [==============================] - 67s 5ms/step - loss: 0.8662 - accuracy: 0.3091\n",
            "Epoch 29/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8668 - accuracy: 0.3133\n",
            "Epoch 30/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8646 - accuracy: 0.3085\n",
            "Epoch 31/50\n",
            "12657/12657 [==============================] - 70s 6ms/step - loss: 0.8633 - accuracy: 0.3081\n",
            "Epoch 32/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8629 - accuracy: 0.3109\n",
            "Epoch 33/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8623 - accuracy: 0.3112\n",
            "Epoch 34/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8623 - accuracy: 0.3100\n",
            "Epoch 35/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8621 - accuracy: 0.3110\n",
            "Epoch 36/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8617 - accuracy: 0.3099\n",
            "Epoch 37/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8611 - accuracy: 0.3126\n",
            "Epoch 38/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8605 - accuracy: 0.3110\n",
            "Epoch 39/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8598 - accuracy: 0.3115\n",
            "Epoch 40/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8587 - accuracy: 0.3118\n",
            "Epoch 41/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8589 - accuracy: 0.3115\n",
            "Epoch 42/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8588 - accuracy: 0.3117\n",
            "Epoch 43/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8578 - accuracy: 0.3117\n",
            "Epoch 44/50\n",
            "12657/12657 [==============================] - 68s 5ms/step - loss: 0.8572 - accuracy: 0.3115\n",
            "Epoch 45/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8573 - accuracy: 0.3126\n",
            "Epoch 46/50\n",
            "12657/12657 [==============================] - 67s 5ms/step - loss: 0.8567 - accuracy: 0.3112\n",
            "Epoch 47/50\n",
            "12657/12657 [==============================] - 69s 5ms/step - loss: 0.8572 - accuracy: 0.3138\n",
            "Epoch 48/50\n",
            "12657/12657 [==============================] - 67s 5ms/step - loss: 0.8563 - accuracy: 0.3099\n",
            "Epoch 49/50\n",
            "12657/12657 [==============================] - 67s 5ms/step - loss: 0.8569 - accuracy: 0.3125\n",
            "Epoch 50/50\n",
            "12657/12657 [==============================] - 66s 5ms/step - loss: 0.8558 - accuracy: 0.3119\n",
            "12657/12657 [==============================] - 22s 2ms/step\n",
            "Metrics for the RF Regressor - 5%\n",
            "RMSE: 0.9208245959792766\n",
            "R2: 0.1515526445568974\n",
            "MAE: 0.6437783231175155\n"
          ]
        }
      ],
      "source": [
        "# Concatenate datasets 1, 2, 3, 4, 5, 7, 8, and 9 for training\n",
        "#train_datasets = [dataset1_sample, dataset2_sample, dataset3_sample, dataset4_sample, dataset5_sample, dataset7_sample, dataset8_sample, dataset9_sample]\n",
        "\n",
        "train_datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9]\n",
        "\n",
        "train_data = pd.concat(train_datasets).reset_index(drop=True)\n",
        "\n",
        "# Separate the training data into features (X) and irregularity data (y)\n",
        "X = train_data.iloc[:, 4:-1]  # Only acceleration data\n",
        "y = train_data[['ALE', 'NLE', 'ALD', 'NLD']]  # Irregularity data\n",
        "z = train_data.iloc[:, -1]\n",
        "\n",
        "# Create the scaler and scale the training features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, z_train, z_test = train_test_split(X_scaled, y, z, test_size=0.1, random_state=42)\n",
        "\n",
        "# Step 1: Train a neural network model for irregularity prediction\n",
        "irregularity_model = Sequential()\n",
        "irregularity_model.add(Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(4))  # 4 output neurons for irregularity columns\n",
        "\n",
        "irregularity_model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "irregularity_model.fit(X_train_scaled, y_train, epochs=50)\n",
        "\n",
        "# Predict irregularity for the training data\n",
        "irregularity_predictions = irregularity_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate evaluation metrics for Step 1\n",
        "mse = mean_squared_error(y_train, irregularity_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_train, irregularity_predictions)\n",
        "r2 = r2_score(y_train, irregularity_predictions)\n",
        "\n",
        "# Print the evaluation metrics for Step 1\n",
        "print(\"Metrics for the RF Regressor - 5%\")\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "X_train_combined = np.column_stack((X_train_scaled, irregularity_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLxfutSjsjiy"
      },
      "source": [
        "Classifier LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iAP-IjFsjiy",
        "outputId": "b9510710-00b6-4886-ad68-a460ce7c68f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 2s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.3447\n",
            "Recall: 0.3710\n",
            "F1-score: 0.3574\n",
            "Accuracy: 0.5442\n",
            "True Positives (TP): 5703\n",
            "False Positives (FP): 10840\n",
            "True Negatives (TN): 18788\n",
            "False Negatives (FN): 9669\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1qKH0WMsjiy"
      },
      "source": [
        "Classifier NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-geGSb7Ssjiy",
        "outputId": "99fca108-7252-4515-f896-4083d449a25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "12657/12657 [==============================] - 43s 3ms/step - loss: 0.5964 - accuracy: 0.6936\n",
            "Epoch 2/10\n",
            "12657/12657 [==============================] - 42s 3ms/step - loss: 0.5905 - accuracy: 0.6986\n",
            "Epoch 3/10\n",
            "12657/12657 [==============================] - 42s 3ms/step - loss: 0.5880 - accuracy: 0.7002\n",
            "Epoch 4/10\n",
            "12657/12657 [==============================] - 42s 3ms/step - loss: 0.5861 - accuracy: 0.7019\n",
            "Epoch 5/10\n",
            "12657/12657 [==============================] - 43s 3ms/step - loss: 0.5846 - accuracy: 0.7029\n",
            "Epoch 6/10\n",
            "12657/12657 [==============================] - 42s 3ms/step - loss: 0.5834 - accuracy: 0.7041\n",
            "Epoch 7/10\n",
            "12657/12657 [==============================] - 42s 3ms/step - loss: 0.5822 - accuracy: 0.7050\n",
            "Epoch 8/10\n",
            "12657/12657 [==============================] - 43s 3ms/step - loss: 0.5816 - accuracy: 0.7057\n",
            "Epoch 9/10\n",
            "12657/12657 [==============================] - 42s 3ms/step - loss: 0.5808 - accuracy: 0.7063\n",
            "Epoch 10/10\n",
            "12657/12657 [==============================] - 42s 3ms/step - loss: 0.5802 - accuracy: 0.7070\n",
            "1407/1407 [==============================] - 2s 2ms/step\n",
            "1407/1407 [==============================] - 2s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.3871\n",
            "Recall: 0.4228\n",
            "F1-score: 0.4042\n",
            "Accuracy: 0.5742\n",
            "True Positives (TP): 6500\n",
            "False Positives (FP): 10290\n",
            "True Negatives (TN): 19338\n",
            "False Negatives (FN): 8872\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a neural network model for damage prediction\n",
        "damage_model5 = Sequential()\n",
        "damage_model5.add(Dense(64, activation='relu', input_dim=X_train_combined.shape[1]))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(1, activation='sigmoid'))  # Output neuron for damage classification\n",
        "\n",
        "damage_model5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "damage_model5.fit(X_train_combined, z_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model5.predict(X_test_combined)\n",
        "\n",
        "# Convert damage probabilities to binary predictions using a threshold\n",
        "threshold = 0.5\n",
        "damage_predictions = (damage_predictions > threshold).astype(int)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olOLDeGssjiy"
      },
      "source": [
        "Classifier XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_koArttWsjiz",
        "outputId": "ae7a15d0-10d3-4e15-bb8a-44af7336f262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 2s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.3589\n",
            "Recall: 0.4385\n",
            "F1-score: 0.3947\n",
            "Accuracy: 0.5406\n",
            "True Positives (TP): 6741\n",
            "False Positives (FP): 12042\n",
            "True Negatives (TN): 17586\n",
            "False Negatives (FN): 8631\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train an XGBoost classifier for damage prediction\n",
        "damage_model2 = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "damage_model2.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model2.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEKAZSGssjiz"
      },
      "source": [
        "Classifier RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da70yvErsjiz",
        "outputId": "7aa4d259-5ca4-41cd-e8d0-d29f8264ba62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 2s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.3533\n",
            "Recall: 0.5086\n",
            "F1-score: 0.4170\n",
            "Accuracy: 0.5141\n",
            "True Positives (TP): 7818\n",
            "False Positives (FP): 14310\n",
            "True Negatives (TN): 15318\n",
            "False Negatives (FN): 7554\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a Random Forest classifier for damage prediction\n",
        "damage_model6 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "damage_model6.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model6.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5Xln4aWsjiz"
      },
      "source": [
        "Classifier Thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgSOMOH6sji0",
        "outputId": "8b18de73-34ad-4c43-81b9-428e1f36fd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1407/1407 [==============================] - 3s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4080\n",
            "Recall: 0.7325\n",
            "F1-score: 0.5240\n",
            "Accuracy: 0.5455\n",
            "True Positives (TP): 11260\n",
            "False Positives (FP): 16341\n",
            "True Negatives (TN): 13287\n",
            "False Negatives (FN): 4112\n"
          ]
        }
      ],
      "source": [
        "# Predict irregularity for the testing data\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "\n",
        "# Compare the predicted irregularities with a threshold to predict damage\n",
        "threshold_ale = 1.5e-3\n",
        "threshold_nle = 2.3e-3\n",
        "threshold_ald = 1.5e-3\n",
        "threshold_nld = 2.3e-3\n",
        "\n",
        "predicted_labels = []\n",
        "for i in range(len(irregularity_predictions)):\n",
        "    if (irregularity_predictions[i, 0] > threshold_ale) or (irregularity_predictions[i, 1] > threshold_nle) or (irregularity_predictions[i, 2] > threshold_ald) or (irregularity_predictions[i, 3] > threshold_nld):\n",
        "        predicted_labels.append(1)\n",
        "    else:\n",
        "        predicted_labels.append(0)\n",
        "\n",
        "# Extract the corresponding labels from the original dataset using the index of the test data\n",
        "actual_labels = z_test.values\n",
        "\n",
        "# Calculate evaluation metrics based on the predicted labels and the actual labels\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "precision = precision_score(actual_labels, predicted_labels)\n",
        "recall = recall_score(actual_labels, predicted_labels)\n",
        "f1 = f1_score(actual_labels, predicted_labels)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbUaD245sji0"
      },
      "source": [
        "#25%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GagAFg41sji0",
        "outputId": "20453227-0866-4f48-e28b-bcf7afab0024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datasets read successfully\n"
          ]
        }
      ],
      "source": [
        "dataset1 = df[0]\n",
        "dataset2 = df[1]\n",
        "dataset3 = df[2]\n",
        "dataset4 = df[3]\n",
        "dataset5 = df[4]\n",
        "dataset6 = df[5]\n",
        "dataset7 = df[6]\n",
        "dataset8 = df[7]\n",
        "dataset9 = df[8]\n",
        "\n",
        "dataset1 = dataset1[:250000]\n",
        "dataset2 = dataset2[:250000]\n",
        "dataset3 = dataset3[:250000]\n",
        "dataset4 = dataset4[:250000]\n",
        "dataset5 = dataset5[:250000]\n",
        "dataset6 = dataset6[:250000]\n",
        "dataset7 = dataset7[:250000]\n",
        "dataset8 = dataset8[:250000]\n",
        "dataset9 = dataset9[:250000]\n",
        "\n",
        "print(\"Datasets read successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dxmwr4Yhsji0"
      },
      "source": [
        "TRAIN STEP 1 REGRESSOR - RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA-Twncbsji0",
        "outputId": "cc506d1b-7c2f-45af-82f3-76ab7fd2ac9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "63282/63282 [==============================] - 206s 3ms/step - loss: 0.9217 - accuracy: 0.3560\n",
            "Epoch 2/25\n",
            "63282/63282 [==============================] - 201s 3ms/step - loss: 0.9127 - accuracy: 0.3616\n",
            "Epoch 3/25\n",
            "63282/63282 [==============================] - 200s 3ms/step - loss: 0.9100 - accuracy: 0.3622\n",
            "Epoch 4/25\n",
            "63282/63282 [==============================] - 198s 3ms/step - loss: 0.9085 - accuracy: 0.3622\n",
            "Epoch 5/25\n",
            "63282/63282 [==============================] - 199s 3ms/step - loss: 0.9074 - accuracy: 0.3623\n",
            "Epoch 6/25\n",
            "63282/63282 [==============================] - 200s 3ms/step - loss: 0.9068 - accuracy: 0.3623\n",
            "Epoch 7/25\n",
            "63282/63282 [==============================] - 198s 3ms/step - loss: 0.9062 - accuracy: 0.3620\n",
            "Epoch 8/25\n",
            "63282/63282 [==============================] - 197s 3ms/step - loss: 0.9057 - accuracy: 0.3614\n",
            "Epoch 9/25\n",
            "63282/63282 [==============================] - 199s 3ms/step - loss: 0.9056 - accuracy: 0.3614\n",
            "Epoch 10/25\n",
            "63282/63282 [==============================] - 200s 3ms/step - loss: 0.9055 - accuracy: 0.3594\n",
            "Epoch 11/25\n",
            "63282/63282 [==============================] - 202s 3ms/step - loss: 0.9053 - accuracy: 0.3585\n",
            "Epoch 12/25\n",
            "63282/63282 [==============================] - 204s 3ms/step - loss: 0.9050 - accuracy: 0.3613\n",
            "Epoch 13/25\n",
            "63282/63282 [==============================] - 204s 3ms/step - loss: 0.9050 - accuracy: 0.3627\n",
            "Epoch 14/25\n",
            "63282/63282 [==============================] - 207s 3ms/step - loss: 0.9050 - accuracy: 0.3639\n",
            "Epoch 15/25\n",
            "63282/63282 [==============================] - 208s 3ms/step - loss: 0.9051 - accuracy: 0.3638\n",
            "Epoch 16/25\n",
            "63282/63282 [==============================] - 212s 3ms/step - loss: 0.9047 - accuracy: 0.3638\n",
            "Epoch 17/25\n",
            "63282/63282 [==============================] - 216s 3ms/step - loss: 0.9047 - accuracy: 0.3636\n",
            "Epoch 18/25\n",
            "63282/63282 [==============================] - 215s 3ms/step - loss: 0.9044 - accuracy: 0.3634\n",
            "Epoch 19/25\n",
            "63282/63282 [==============================] - 210s 3ms/step - loss: 0.9042 - accuracy: 0.3633\n",
            "Epoch 20/25\n",
            "63282/63282 [==============================] - 210s 3ms/step - loss: 0.9040 - accuracy: 0.3632\n",
            "Epoch 21/25\n",
            "63282/63282 [==============================] - 209s 3ms/step - loss: 0.9038 - accuracy: 0.3633\n",
            "Epoch 22/25\n",
            "63282/63282 [==============================] - 212s 3ms/step - loss: 0.9038 - accuracy: 0.3628\n",
            "Epoch 23/25\n",
            "63282/63282 [==============================] - 212s 3ms/step - loss: 0.9037 - accuracy: 0.3629\n",
            "Epoch 24/25\n",
            "63282/63282 [==============================] - 216s 3ms/step - loss: 0.9039 - accuracy: 0.3632\n",
            "Epoch 25/25\n",
            "63282/63282 [==============================] - 218s 3ms/step - loss: 0.9036 - accuracy: 0.3628\n",
            "63282/63282 [==============================] - 88s 1ms/step\n",
            "Metrics for the RF Regressor - 25%\n",
            "RMSE: 0.9502293466158085\n",
            "R2: 0.09692057647840813\n",
            "MAE: 0.7185941739533019\n"
          ]
        }
      ],
      "source": [
        "# Concatenate datasets 1, 2, 3, 4, 5, 7, 8, and 9 for training\n",
        "#train_datasets = [dataset1_sample, dataset2_sample, dataset3_sample, dataset4_sample, dataset5_sample, dataset7_sample, dataset8_sample, dataset9_sample]\n",
        "\n",
        "train_datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9]\n",
        "\n",
        "train_data = pd.concat(train_datasets).reset_index(drop=True)\n",
        "\n",
        "# Separate the training data into features (X) and irregularity data (y)\n",
        "X = train_data.iloc[:, 4:-1]  # Only acceleration data\n",
        "y = train_data[['ALE', 'NLE', 'ALD', 'NLD']]  # Irregularity data\n",
        "z = train_data.iloc[:, -1]\n",
        "\n",
        "# Create the scaler and scale the training features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, z_train, z_test = train_test_split(X_scaled, y, z, test_size=0.1, random_state=42)\n",
        "\n",
        "# Step 1: Train a neural network model for irregularity prediction\n",
        "irregularity_model = Sequential()\n",
        "irregularity_model.add(Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(4))  # 4 output neurons for irregularity columns\n",
        "\n",
        "irregularity_model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "irregularity_model.fit(X_train_scaled, y_train, epochs=25)\n",
        "\n",
        "# Predict irregularity for the training data\n",
        "irregularity_predictions = irregularity_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate evaluation metrics for Step 1\n",
        "mse = mean_squared_error(y_train, irregularity_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_train, irregularity_predictions)\n",
        "r2 = r2_score(y_train, irregularity_predictions)\n",
        "\n",
        "# Print the evaluation metrics for Step 1\n",
        "print(\"Metrics for the RF Regressor - 25%\")\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Step 2: Train an SVC model for damage prediction\n",
        "X_train_combined = np.column_stack((X_train_scaled, irregularity_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtiaVpgtsji0"
      },
      "source": [
        "Classifier LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-0qZDqOsji1",
        "outputId": "918c490d-0bba-49ba-f8c5-3711b66f66cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7032/7032 [==============================] - 10s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4215\n",
            "Recall: 0.5093\n",
            "F1-score: 0.4613\n",
            "Accuracy: 0.5209\n",
            "True Positives (TP): 46153\n",
            "False Positives (FP): 63337\n",
            "True Negatives (TN): 71049\n",
            "False Negatives (FN): 44461\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnXg1mgmsji1"
      },
      "source": [
        "Classifier NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B671Uh3Lsji1",
        "outputId": "03645c03-580f-4b77-ed56-f1010d82d55d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63282/63282 [==============================] - 212s 3ms/step - loss: 0.6340 - accuracy: 0.6478\n",
            "Epoch 2/10\n",
            "63282/63282 [==============================] - 205s 3ms/step - loss: 0.6313 - accuracy: 0.6505\n",
            "Epoch 3/10\n",
            "63282/63282 [==============================] - 211s 3ms/step - loss: 0.6302 - accuracy: 0.6519\n",
            "Epoch 4/10\n",
            "63282/63282 [==============================] - 209s 3ms/step - loss: 0.6294 - accuracy: 0.6527\n",
            "Epoch 5/10\n",
            "63282/63282 [==============================] - 209s 3ms/step - loss: 0.6289 - accuracy: 0.6531\n",
            "Epoch 6/10\n",
            "63282/63282 [==============================] - 211s 3ms/step - loss: 0.6284 - accuracy: 0.6533\n",
            "Epoch 7/10\n",
            "63282/63282 [==============================] - 214s 3ms/step - loss: 0.6281 - accuracy: 0.6539\n",
            "Epoch 8/10\n",
            "63282/63282 [==============================] - 207s 3ms/step - loss: 0.6278 - accuracy: 0.6542\n",
            "Epoch 9/10\n",
            "63282/63282 [==============================] - 208s 3ms/step - loss: 0.6275 - accuracy: 0.6543\n",
            "Epoch 10/10\n",
            "63282/63282 [==============================] - 208s 3ms/step - loss: 0.6273 - accuracy: 0.6547\n",
            "7032/7032 [==============================] - 10s 1ms/step\n",
            "7032/7032 [==============================] - 9s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4270\n",
            "Recall: 0.5458\n",
            "F1-score: 0.4792\n",
            "Accuracy: 0.5221\n",
            "True Positives (TP): 49461\n",
            "False Positives (FP): 66364\n",
            "True Negatives (TN): 68022\n",
            "False Negatives (FN): 41153\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a neural network model for damage prediction\n",
        "damage_model5 = Sequential()\n",
        "damage_model5.add(Dense(64, activation='relu', input_dim=X_train_combined.shape[1]))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(1, activation='sigmoid'))  # Output neuron for damage classification\n",
        "\n",
        "damage_model5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "damage_model5.fit(X_train_combined, z_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model5.predict(X_test_combined)\n",
        "\n",
        "# Convert damage probabilities to binary predictions using a threshold\n",
        "threshold = 0.5\n",
        "damage_predictions = (damage_predictions > threshold).astype(int)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erIHtW_ysji1"
      },
      "source": [
        "Classifier XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5NCBrwvsji1",
        "outputId": "25081f53-c788-46db-8e6f-b12e2f161e92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7032/7032 [==============================] - 10s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4213\n",
            "Recall: 0.5960\n",
            "F1-score: 0.4937\n",
            "Accuracy: 0.5077\n",
            "True Positives (TP): 54009\n",
            "False Positives (FP): 74172\n",
            "True Negatives (TN): 60214\n",
            "False Negatives (FN): 36605\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train an XGBoost classifier for damage prediction\n",
        "damage_model2 = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "damage_model2.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model2.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pVWGl1usji1"
      },
      "source": [
        "Classifier RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvS97IxPsji1",
        "outputId": "24d248fe-ee19-422f-a03c-370a1a15e4c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7032/7032 [==============================] - 10s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4164\n",
            "Recall: 0.6045\n",
            "F1-score: 0.4931\n",
            "Accuracy: 0.4994\n",
            "True Positives (TP): 54779\n",
            "False Positives (FP): 76789\n",
            "True Negatives (TN): 57597\n",
            "False Negatives (FN): 35835\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a Random Forest classifier for damage prediction\n",
        "damage_model6 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "damage_model6.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model6.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAnhKNdxsji2"
      },
      "source": [
        "Classifier Thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHiITo9isji2",
        "outputId": "b137d022-fc6d-4ae8-b559-fb4a7e38442d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7032/7032 [==============================] - 9s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4680\n",
            "Recall: 0.7597\n",
            "F1-score: 0.5792\n",
            "Accuracy: 0.5554\n",
            "True Positives (TP): 68842\n",
            "False Positives (FP): 78253\n",
            "True Negatives (TN): 56133\n",
            "False Negatives (FN): 21772\n"
          ]
        }
      ],
      "source": [
        "# Predict irregularity for the testing data\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "\n",
        "# Compare the predicted irregularities with a threshold to predict damage\n",
        "threshold_ale = 1.5e-3\n",
        "threshold_nle = 2.3e-3\n",
        "threshold_ald = 1.5e-3\n",
        "threshold_nld = 2.3e-3\n",
        "\n",
        "predicted_labels = []\n",
        "for i in range(len(irregularity_predictions)):\n",
        "    if (irregularity_predictions[i, 0] > threshold_ale) or (irregularity_predictions[i, 1] > threshold_nle) or (irregularity_predictions[i, 2] > threshold_ald) or (irregularity_predictions[i, 3] > threshold_nld):\n",
        "        predicted_labels.append(1)\n",
        "    else:\n",
        "        predicted_labels.append(0)\n",
        "\n",
        "# Extract the corresponding labels from the original dataset using the index of the test data\n",
        "actual_labels = z_test.values\n",
        "\n",
        "# Calculate evaluation metrics based on the predicted labels and the actual labels\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "precision = precision_score(actual_labels, predicted_labels)\n",
        "recall = recall_score(actual_labels, predicted_labels)\n",
        "f1 = f1_score(actual_labels, predicted_labels)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0yuXrgfsji2"
      },
      "source": [
        "#100%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsyX39MWsji2",
        "outputId": "28b0c9c7-3362-457d-e8cc-08c355662dfb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets read successfully\n"
          ]
        }
      ],
      "source": [
        "dataset1 = df[0]\n",
        "dataset2 = df[1]\n",
        "dataset3 = df[2]\n",
        "dataset4 = df[3]\n",
        "dataset5 = df[4]\n",
        "dataset6 = df[5]\n",
        "dataset7 = df[6]\n",
        "dataset8 = df[7]\n",
        "dataset9 = df[8]\n",
        "\n",
        "dataset1 = dataset1[:1000000]\n",
        "dataset2 = dataset2[:1000000]\n",
        "dataset3 = dataset3[:1000000]\n",
        "dataset4 = dataset4[:1000000]\n",
        "dataset5 = dataset5[:1000000]\n",
        "dataset6 = dataset6[:1000000]\n",
        "dataset7 = dataset7[:1000000]\n",
        "dataset8 = dataset8[:1000000]\n",
        "dataset9 = dataset9[:1000000]\n",
        "\n",
        "print(\"Datasets read successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a0ZnwVjsji3"
      },
      "source": [
        "TRAIN STEP 1 REGRESSOR - RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmKQbWvvsji3",
        "outputId": "e0bbc114-609e-4115-9852-1784084ffe68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "253125/253125 [==============================] - 361s 1ms/step - loss: 0.9055\n",
            "Epoch 2/15\n",
            "253125/253125 [==============================] - 359s 1ms/step - loss: 0.9011\n",
            "Epoch 3/15\n",
            "253125/253125 [==============================] - 353s 1ms/step - loss: 0.9001\n",
            "Epoch 4/15\n",
            "253125/253125 [==============================] - 342s 1ms/step - loss: 0.8995\n",
            "Epoch 5/15\n",
            "253125/253125 [==============================] - 327s 1ms/step - loss: 0.8992\n",
            "Epoch 6/15\n",
            "253125/253125 [==============================] - 322s 1ms/step - loss: 0.8989\n",
            "Epoch 7/15\n",
            "253125/253125 [==============================] - 341s 1ms/step - loss: 0.8988\n",
            "Epoch 8/15\n",
            "253125/253125 [==============================] - 330s 1ms/step - loss: 0.8987\n",
            "Epoch 9/15\n",
            "253125/253125 [==============================] - 353s 1ms/step - loss: 0.8985\n",
            "Epoch 10/15\n",
            "253125/253125 [==============================] - 373s 1ms/step - loss: 0.8984\n",
            "Epoch 11/15\n",
            "253125/253125 [==============================] - 353s 1ms/step - loss: 0.8983\n",
            "Epoch 12/15\n",
            "253125/253125 [==============================] - 340s 1ms/step - loss: 0.8982\n",
            "Epoch 13/15\n",
            "253125/253125 [==============================] - 322s 1ms/step - loss: 0.8982\n",
            "Epoch 14/15\n",
            "253125/253125 [==============================] - 319s 1ms/step - loss: 0.8982\n",
            "Epoch 15/15\n",
            "253125/253125 [==============================] - 317s 1ms/step - loss: 0.8981\n",
            "253125/253125 [==============================] - 214s 843us/step\n",
            "Metrics for the RF Regressor - 100%\n",
            "RMSE: 0.9488791677402734\n",
            "R2: 0.09957112462702766\n",
            "MAE: 0.743567760122282\n"
          ]
        }
      ],
      "source": [
        "# Concatenate datasets 1, 2, 3, 4, 5, 7, 8, and 9 for training\n",
        "#train_datasets = [dataset1_sample, dataset2_sample, dataset3_sample, dataset4_sample, dataset5_sample, dataset7_sample, dataset8_sample, dataset9_sample]\n",
        "\n",
        "train_datasets = [dataset1, dataset2, dataset3, dataset4, dataset5, dataset6, dataset7, dataset8, dataset9]\n",
        "\n",
        "train_data = pd.concat(train_datasets).reset_index(drop=True)\n",
        "\n",
        "# Separate the training data into features (X) and irregularity data (y)\n",
        "X = train_data.iloc[:, 4:-1]  # Only acceleration data\n",
        "y = train_data[['ALE', 'NLE', 'ALD', 'NLD']]  # Irregularity data\n",
        "z = train_data.iloc[:, -1]\n",
        "\n",
        "# Create the scaler and scale the training features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "y = scaler.fit_transform(y)\n",
        "\n",
        "X_train_scaled, X_test_scaled, y_train, y_test, z_train, z_test = train_test_split(X_scaled, y, z, test_size=0.1, random_state=42)\n",
        "\n",
        "# Step 1: Train a neural network model for irregularity prediction\n",
        "irregularity_model = Sequential()\n",
        "irregularity_model.add(Dense(64, activation='relu', input_dim=X_train_scaled.shape[1]))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(64, activation='relu'))\n",
        "irregularity_model.add(Dense(4))  # 4 output neurons for irregularity columns\n",
        "\n",
        "irregularity_model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.001))\n",
        "irregularity_model.fit(X_train_scaled, y_train, epochs=15)\n",
        "\n",
        "# Predict irregularity for the training data\n",
        "irregularity_predictions = irregularity_model.predict(X_train_scaled)\n",
        "\n",
        "# Calculate evaluation metrics for Step 1\n",
        "mse = mean_squared_error(y_train, irregularity_predictions)\n",
        "rmse = np.sqrt(mse)\n",
        "mae = mean_absolute_error(y_train, irregularity_predictions)\n",
        "r2 = r2_score(y_train, irregularity_predictions)\n",
        "\n",
        "# Print the evaluation metrics for Step 1\n",
        "print(\"Metrics for the RF Regressor - 100%\")\n",
        "print(\"RMSE:\", rmse)\n",
        "print(\"R2:\", r2)\n",
        "print(\"MAE:\", mae)\n",
        "\n",
        "# Step 2: Train an SVC model for damage prediction\n",
        "X_train_combined = np.column_stack((X_train_scaled, irregularity_predictions))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQoeG7DGsji4"
      },
      "source": [
        "Classifier Thresholds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3Ar4v-vesji5",
        "outputId": "f1c4ffb6-b99a-4dab-9c17-aaed2710cb98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28125/28125 [==============================] - 49s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4992\n",
            "Recall: 0.7071\n",
            "F1-score: 0.5853\n",
            "Accuracy: 0.5908\n",
            "True Positives (TP): 259844\n",
            "False Positives (FP): 260626\n",
            "True Negatives (TN): 271871\n",
            "False Negatives (FN): 107659\n"
          ]
        }
      ],
      "source": [
        "# Predict irregularity for the testing data\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "\n",
        "# Compare the predicted irregularities with a threshold to predict damage\n",
        "threshold_ale = 1.5e-3\n",
        "threshold_nle = 2.3e-3\n",
        "threshold_ald = 1.5e-3\n",
        "threshold_nld = 2.3e-3\n",
        "\n",
        "predicted_labels = []\n",
        "for i in range(len(irregularity_predictions)):\n",
        "    if (irregularity_predictions[i, 0] > threshold_ale) or (irregularity_predictions[i, 1] > threshold_nle) or (irregularity_predictions[i, 2] > threshold_ald) or (irregularity_predictions[i, 3] > threshold_nld):\n",
        "        predicted_labels.append(1)\n",
        "    else:\n",
        "        predicted_labels.append(0)\n",
        "\n",
        "# Extract the corresponding labels from the original dataset using the index of the test data\n",
        "actual_labels = z_test.values\n",
        "\n",
        "# Calculate evaluation metrics based on the predicted labels and the actual labels\n",
        "accuracy = accuracy_score(actual_labels, predicted_labels)\n",
        "precision = precision_score(actual_labels, predicted_labels)\n",
        "recall = recall_score(actual_labels, predicted_labels)\n",
        "f1 = f1_score(actual_labels, predicted_labels)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, predicted_labels)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEiOeTiCsji3"
      },
      "source": [
        "Classifier LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsJ_7xLVsji3",
        "outputId": "23cca2d1-1742-493c-e9df-4ee4c0116521"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28125/28125 [==============================] - 40s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4304\n",
            "Recall: 0.4907\n",
            "F1-score: 0.4586\n",
            "Accuracy: 0.5269\n",
            "True Positives (TP): 180319\n",
            "False Positives (FP): 238649\n",
            "True Negatives (TN): 293848\n",
            "False Negatives (FN): 187184\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a LightGBM classifier for damage prediction\n",
        "damage_model3 = lgb.LGBMClassifier(n_estimators=50, random_state=42)\n",
        "damage_model3.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model3.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgnGVpKGsji3"
      },
      "source": [
        "Classifier NEURAL NETWORK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpOmtDRlsji3",
        "outputId": "f747b70b-4597-42d2-b2e7-b40a17101a44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "253125/253125 [==============================] - 535s 2ms/step - loss: 0.6320 - accuracy: 0.6502\n",
            "Epoch 2/10\n",
            "253125/253125 [==============================] - 529s 2ms/step - loss: 0.6312 - accuracy: 0.6511\n",
            "Epoch 3/10\n",
            "253125/253125 [==============================] - 536s 2ms/step - loss: 0.6310 - accuracy: 0.6514\n",
            "Epoch 4/10\n",
            "253125/253125 [==============================] - 549s 2ms/step - loss: 0.6307 - accuracy: 0.6517\n",
            "Epoch 5/10\n",
            "253125/253125 [==============================] - 550s 2ms/step - loss: 0.6307 - accuracy: 0.6517\n",
            "Epoch 6/10\n",
            "253125/253125 [==============================] - 551s 2ms/step - loss: 0.6305 - accuracy: 0.6519\n",
            "Epoch 7/10\n",
            "253125/253125 [==============================] - 549s 2ms/step - loss: 0.6305 - accuracy: 0.6520\n",
            "Epoch 8/10\n",
            "253125/253125 [==============================] - 540s 2ms/step - loss: 0.6304 - accuracy: 0.6522\n",
            "Epoch 9/10\n",
            "253125/253125 [==============================] - 546s 2ms/step - loss: 0.6303 - accuracy: 0.6523\n",
            "Epoch 10/10\n",
            "253125/253125 [==============================] - 555s 2ms/step - loss: 0.6304 - accuracy: 0.6522\n",
            "28125/28125 [==============================] - 46s 2ms/step\n",
            "28125/28125 [==============================] - 41s 1ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4335\n",
            "Recall: 0.4822\n",
            "F1-score: 0.4565\n",
            "Accuracy: 0.5313\n",
            "True Positives (TP): 177195\n",
            "False Positives (FP): 231563\n",
            "True Negatives (TN): 300934\n",
            "False Negatives (FN): 190308\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a neural network model for damage prediction\n",
        "damage_model5 = Sequential()\n",
        "damage_model5.add(Dense(64, activation='relu', input_dim=X_train_combined.shape[1]))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(64, activation='relu'))\n",
        "damage_model5.add(Dense(1, activation='sigmoid'))  # Output neuron for damage classification\n",
        "\n",
        "damage_model5.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "damage_model5.fit(X_train_combined, z_train, epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model5.predict(X_test_combined)\n",
        "\n",
        "# Convert damage probabilities to binary predictions using a threshold\n",
        "threshold = 0.5\n",
        "damage_predictions = (damage_predictions > threshold).astype(int)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DxwmR07sji4"
      },
      "source": [
        "Classifier XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLbGuCbIsji4",
        "outputId": "eb7dc52b-bd26-4ae8-991a-f6e205fe3317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28125/28125 [==============================] - 44s 2ms/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4265\n",
            "Recall: 0.4918\n",
            "F1-score: 0.4568\n",
            "Accuracy: 0.5225\n",
            "True Positives (TP): 180735\n",
            "False Positives (FP): 243014\n",
            "True Negatives (TN): 289483\n",
            "False Negatives (FN): 186768\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train an XGBoost classifier for damage prediction\n",
        "damage_model2 = xgb.XGBClassifier(n_estimators=50, random_state=42)\n",
        "damage_model2.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model2.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlujBfrFsji4"
      },
      "source": [
        "Classifier RANDOM FOREST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gdm53oejsji4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e002f4d4-c3ab-45fd-9c33-e4f5af4cdfe6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28125/28125 [==============================] - 26s 920us/step\n",
            "Evaluation Metrics:\n",
            "Precision: 0.4192\n",
            "Recall: 0.5872\n",
            "F1-score: 0.4892\n",
            "Accuracy: 0.4993\n",
            "True Positives (TP): 215782\n",
            "False Positives (FP): 298941\n",
            "True Negatives (TN): 233556\n",
            "False Negatives (FN): 151721\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Train a Random Forest classifier for damage prediction\n",
        "damage_model6 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "damage_model6.fit(X_train_combined, z_train)\n",
        "\n",
        "# Step 3: Use the trained models for prediction on dataset6_sample\n",
        "irregularity_predictions = irregularity_model.predict(X_test_scaled)\n",
        "X_test_combined = np.column_stack((irregularity_predictions, X_test_scaled))\n",
        "damage_predictions = damage_model6.predict(X_test_combined)\n",
        "\n",
        "actual_labels = z_test.values\n",
        "accuracy = accuracy_score(actual_labels, damage_predictions)\n",
        "precision = precision_score(actual_labels, damage_predictions)\n",
        "recall = recall_score(actual_labels, damage_predictions)\n",
        "f1 = f1_score(actual_labels, damage_predictions)\n",
        "\n",
        "print(\"Evaluation Metrics:\")\n",
        "print(\"Precision: {:.4f}\".format(precision))\n",
        "print(\"Recall: {:.4f}\".format(recall))\n",
        "print(\"F1-score: {:.4f}\".format(f1))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy))\n",
        "\n",
        "cm = confusion_matrix(actual_labels, damage_predictions)\n",
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "print(\"True Positives (TP):\", tp)\n",
        "print(\"False Positives (FP):\", fp)\n",
        "print(\"True Negatives (TN):\", tn)\n",
        "print(\"False Negatives (FN):\", fn)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "sjV763VvWzM6",
        "0RdcD4TOW3aO",
        "i4f8IPmNsjin",
        "U9oOkXtXsjix",
        "XbUaD245sji0"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}